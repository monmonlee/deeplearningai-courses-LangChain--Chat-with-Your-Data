{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval augmented generation\n",
    " \n",
    "In retrieval augmented generation (RAG), an LLM retrieves contextual documents from an external dataset as part of its execution. \n",
    "\n",
    "This is useful if we want to ask question about specific documents (e.g., our PDFs, a set of videos, etc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain openai dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 小筆記：為什麼用 %pip 會比 !pip 還好？\n",
    "解答：\n",
    "* !pip = 在旁邊開個小視窗偷偷叫系統去幫你安裝，結果可能裝到別的房間。\n",
    "* %pip = 直接跟 Notebook 的 kernel 說「幫我裝這個套件」，保證裝到正確的房間。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "目的：建立langchain + openai 的基礎環境\n",
    "'''\n",
    "#! pip install langchain\n",
    "import os # 作業系統相關功能（讀取環境變數）\n",
    "import openai # openai api 客戶端\n",
    "# import sys # python 系統功能，下載到地端用不到\n",
    "# sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv # dotenv 是專門用來讀取.env套件的套件，並接上環境\n",
    "_ = load_dotenv(find_dotenv()) # 讀取.env檔案\n",
    "\n",
    "'''\n",
    "為什麼要這樣寫？\n",
    "find_dotenv() → 自動尋找 .env 檔案（向上搜尋資料夾）\n",
    "load_dotenv() → 載入 .env 檔案到環境變數\n",
    "_ = → 把回傳值丟掉（不需要）\n",
    "load_dotenv() 會回傳什麼？\n",
    "ans:會回傳true, false，但我們只要結果就好不需要回傳值\n",
    "一般 : \"result = load_doenv()\" → 有回傳值\n",
    "如果不要 : \"_ = load_doenv()\" → 自動忽略回傳值（pythin 慣例）\n",
    "\n",
    "'''\n",
    "\n",
    "# 載入 api key\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDFs\n",
    "\n",
    "Let's load a PDF [transcript](https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf) from Andrew Ng's famous CS229 course! These documents are the result of automated transcription so words and sentences are sometimes split unexpectedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain-community pypdf\n",
    "'''\n",
    "套件介紹\n",
    "1. langchain-community：包含現在要使用的document_loaders、向量資料庫、llm整合（hugging face, anthropic）\n",
    "2. pypdf：專門處理pdf檔案得python套件（用來解析pdf）\n",
    "-U 是什麼？\n",
    "ans：等於--upgrade，如果已經裝了，升級到最新的版本\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The course will show the pip installs you would need to install packages on your own machine.\n",
    "# These packages are already installed on this platform and should not be run again.\n",
    "#! pip install pypdf \n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader # PyPDFLoader：LangChain 的 PDF 文件載入器，專門把pdf檔案轉換成langchain形式\n",
    "# 建立載入器實例（指定來源）\n",
    "loader = PyPDFLoader(\"https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf\")\n",
    "# 實際載入檔案：下載/讀取 PDF → 用 pypdf 解析 → 分頁處理 → 轉成 Document 格式\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總共載入了 22 頁\n",
      "第一頁內容：MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is just spend a little time going over the logistics \n",
      "of...\n",
      "第一頁 metadata：{'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2008-07-11T11:25:23-07:00', 'author': '', 'moddate': '2008-07-11T11:25:23-07:00', 'title': '', 'source': 'https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf', 'total_pages': 22, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "# 實際看看結果\n",
    "print(f\"總共載入了 {len(pages)} 頁\")\n",
    "print(f\"第一頁內容：{pages[0].page_content[:200]}...\")\n",
    "print(f\"第一頁 metadata：{pages[0].metadata}\")\n",
    "\n",
    "\n",
    "\n",
    "# len(pages) → 了解有多少頁\n",
    "# 字串切片 + .page_content → 看到某頁的頁面內容\n",
    "# 字串切片 + .metadata → 看到某頁的 meta data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 小筆記\n",
    "##### 1. meta data 的功能是什麼？\n",
    "* 追蹤來源：如果是rag，有了mata data如果使用者詢問資料出處可以查詢。\n",
    "* 過濾與搜尋：搜尋時可以只搜尋某一頁、某個日期、某個來源\n",
    "    ```python\n",
    "    # 只搜尋特定頁面\n",
    "    first_5_pages = [p for p in pages if p.metadata['page'] < 5]\n",
    "    ```\n",
    "##### 2. 通常 meta data 有那些格式？\n",
    "```python\n",
    "{\n",
    "    'source': 'https://see.stanford.edu/.../MachineLearning-Lecture01.pdf',\n",
    "    'page': 0,           # 第幾頁（從0開始）\n",
    "    'total_pages': 20,   # 總頁數\n",
    "    'title': 'Machine Learning CS229 Lecture 1',\n",
    "    'author': 'Stanford University',\n",
    "    'creation_date': '2023-01-15',\n",
    "    'file_size': '2.5MB'\n",
    "}\n",
    "```\n",
    "##### 3. 為什麼程式裡沒有看到 pypdf 的作用，但還要安裝？\n",
    "* LangChain 比較像是「封裝」或是中間轉換器，不會參與解析 pdf\n",
    "    * 呼叫外部的 PDF 解析套件（如 pypdf）→ 把頁面內容抽出來\n",
    "    * 再把抽出來的文字包裝成 LangChain 的 Document 物件，方便後面使用\n",
    "* 真正解析的仍舊是 pypdf\n",
    "* 這樣設計的原因：保持 LangChain 輕量，採取「lazy dependency（延遲依賴）」策略\n",
    "* 備註：pdf 轉成langchain document 完全沒有用到 llm api～"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 小筆記：音檔轉文字作法上的差異\n",
    "* 課本示範方式：youtube影片 → 下載音檔  → llm轉換成文字 → 載入到langchain\n",
    "    * 遇到的問題：是透過地端操作且用自己的openai api服務，所以此方法除了要下載許多套件、也要計費\n",
    "    * 解決方法：將影片替換成更短的影片練習\n",
    "* 偷吃步方式：直接讀取影片的逐字稿 → 載入到langchain（但這樣就沒有用ai)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install yt_dlp pydub ffmpeg-python ffmpeg ffprobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders import FileSystemBlobLoader # 2025.08.19 位置改了, 原本在document_loaders.generic裡面\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser \n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 小筆記 - 各種套件介紹\n",
    "\n",
    "音檔處理相關：\n",
    "\n",
    "* yt_dlp：下載 youtube 音檔的工具\n",
    "* pydub：python 音檔處理套件\n",
    "* ffmpeg-python：讓 py 可以呼叫 ffmpeg 套件\n",
    "* ffmpeg：Python 環境中的 ffmpeg 介面（注意：真正的 ffmpe 要去 homebrew 下載）\n",
    "\n",
    "LangChain 載入器：\n",
    "\n",
    "* GenericLoader： 通用載入＆解析框架\n",
    "* FileSystemBlobLoader：從本地檔案系統載入檔案（載入器）\n",
    "* OpenAIWhisperParser：把音檔轉為文字（解析器）\n",
    "* YoutubeAudioLoader：youtube檔案載入（載入器）\n",
    "\n",
    "運作流程：\n",
    "1. YoutubeAudioLoader （和 FileSystemBlobLoader 擇一）\n",
    "   \n",
    "   ↓ (使用 yt_dlp)\n",
    "   下載 YouTube 影片\n",
    "   \n",
    "2. ffmpeg/pydub\n",
    "   \n",
    "   ↓ (處理音檔格式)\n",
    "   轉換成 Whisper 可用格式\n",
    "   \n",
    "3. FileSystemBlobLoader （和 YoutubeAudioLoader 擇一）\n",
    "   \n",
    "   ↓ (讀取本地檔案)\n",
    "   載入處理好的音檔\n",
    "   \n",
    "4. OpenAIWhisperParser\n",
    "   \n",
    "   ↓ (呼叫 OpenAI API)\n",
    "   轉錄成文字\n",
    "   \n",
    "5. GenericLoader\n",
    "   \n",
    "   ↓ (協調整個流程)\n",
    "   包裝成 LangChain Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing part 1!\n"
     ]
    }
   ],
   "source": [
    "url=\"https://www.youtube.com/watch?v=rEDzUT3ymw4\"\n",
    "save_dir=\"/Users/mangtinglee/Desktop/2025_gap_careerpath/ai_agent/youtube/\"\n",
    "os.makedirs(save_dir, exist_ok=True) # 這行會自動建立資料夾（如果不存在）\n",
    "loader = GenericLoader( # GenericLoader 只能接受兩個參數\n",
    "    # YoutubeAudioLoader([url],save_dir),  # fetch from youtube 下載到本地 － 讀取器之一\n",
    "    FileSystemBlobLoader(save_dir, glob=\"*.mp4\"),   #fetch locally － 讀取器之二\n",
    "    OpenAIWhisperParser() # 透過 openai api 轉錄 - 也就是解析器\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Transcribing part 1!' →  OpenAI Whisper API 的內建訊息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '/Users/mangtinglee/Desktop/2025_gap_careerpath/ai_agent/youtube/Explained In A Minute： Neural Networks.mp4', 'chunk': 0}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 小筆記 - GenericLoader 設計與功用\n",
    "* GenericLoader ＝ 不同檔案的通用框架，也可以像pdf、urls一樣使用專用的框架也行（PyPDFLoader, WebBaseLoader）\n",
    "* GenericLoader 的設計（只會接受2個參數）：\n",
    "    ```python\n",
    "    GenericLoader(\n",
    "        blob_loader, # 負責「載入資料」\n",
    "        parser # 負責「解析資料」\n",
    "    )\n",
    "    ``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Users/mangtinglee/Desktop/useful_code/kaggle_env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-community beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://github.com/basecamp/handbook/blob/master/titles-for-programmers.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "為什麼回傳網頁會有大量空白和亂碼？\n",
    "* BeautifulSoup 萃取所有文字，會把HTML標籤移除，只留下結構"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow steps [here](https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/notion) for an example Notion site such as [this one](https://yolospace.notion.site/Blendle-s-Employee-Handbook-e31bff7da17346ee99f531087d8b133f):\n",
    "\n",
    "* Duplicate the page into your own Notion space and export as `Markdown / CSV`.\n",
    "* Unzip it and save it as a folder that contains the markdown file for the Notion page.\n",
    "* 注意： NotionDirectoryLoader 吃「資料夾路徑」\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "loader = NotionDirectoryLoader(\"/Users/mangtinglee/Desktop\")\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 新工作之旅\n",
      "\n",
      "<aside>\n",
      "💡\n",
      "\n",
      "**最壞的情況是什麼？最多就是第一份AI工作薪資不夠理想，但你已經進入這個領域了，後面的路會越走越寬！**\n",
      "\n",
      "</aside>\n",
      "\n",
      "[Claude](https:\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '/Users/mangtinglee/Desktop/新工作之旅 21e2fef0ad76802bbbc5da7234a7fda2.md'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('kaggle_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e79b4bf471fd6abf0718459ed859a2866e15f0fa4ac4da492093930a8ca504d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
