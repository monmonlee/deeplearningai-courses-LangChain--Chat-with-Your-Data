{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0689733d",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "\n",
    "Retrieval is the centerpiece of our retrieval augmented generation (RAG) flow. \n",
    "\n",
    "Let's get our vectorDB from before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23621cb5",
   "metadata": {},
   "source": [
    "### 課程補充：檢索方式－maximum marginal relevance (MMR)最大邊際相關性\n",
    "- 不只有「最接近的」回答，而是多元的所有回答（既相關又有多元性），因為 similarity 搜尋都會返回最相關但都可能是重複的資訊\n",
    "- 演算法公式：\n",
    "    - `MMR = λ * Similarity(query, doc) - (1-λ) * max(Similarity(doc, selected_docs))`\n",
    "    - λ：介於0-1的數字，決定要「相關重要」還是「多樣化重要」\n",
    "    - 這個公式基本上就是「相關性」－「多樣性」，所以 λ 的數值決定結果比較偏向多樣還是相關\n",
    "    - query：問題的向量、doc：篩選出的回答的向量（多半為複數)，Similarity(query, doc)越高代表與回答與問題的相關性越高（點積）\n",
    "    - 運行邏輯：\n",
    "        - 1. 先由相似度選出 fetch_k 個相關的回答（ fetch_k langchain 預設 20 ）\n",
    "        - 2. 開始進入mmr的篩選，第一輪：\n",
    "                ```python\n",
    "                已選文件 = []  # 還沒選任何文件\n",
    "\n",
    "                # 計算每個候選文件的MMR\n",
    "                MMR_A = λ * Sim(query, A) - (1-λ) * 0  # 沒有已選文件，所以max=0\n",
    "                MMR_B = λ * Sim(query, B) - (1-λ) * 0\n",
    "                MMR_C = λ * Sim(query, C) - (1-λ) * 0\n",
    "                MMR_D = λ * Sim(query, D) - (1-λ) * 0  \n",
    "                MMR_E = λ * Sim(query, E) - (1-λ) * 0\n",
    "\n",
    "                # 假設A分數最高，選擇A\n",
    "                已選文件 = [A]\n",
    "                ```\n",
    "        - 3. 第二輪，直到已選文件達到 k = n ：\n",
    "                ```python\n",
    "                已選文件 = [A]  # 現在有一個已選文件了\n",
    "\n",
    "                # 從剩下的候選文件中選擇\n",
    "                MMR_B = λ * Sim(query, B) - (1-λ) * Sim(B, A)\n",
    "                MMR_C = λ * Sim(query, C) - (1-λ) * Sim(C, A)  \n",
    "                MMR_D = λ * Sim(query, D) - (1-λ) * Sim(D, A)\n",
    "                MMR_E = λ * Sim(query, E) - (1-λ) * Sim(E, A)\n",
    "\n",
    "                # 假設C分數最高，選擇C\n",
    "                已選文件 = [A, C]\n",
    "                ```            \n",
    "- 文件檢索流程（先相關性，再MMR）：\n",
    "    - 先找出一堆相關的候選文件\n",
    "    - 從其中挑選出前fetch_k相關的\n",
    "    - 用MMR從fetch_k挑選出最終的k個"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3636ef",
   "metadata": {},
   "source": [
    "### 課堂補充：檢索方式 － LLM aided retrival\n",
    "- 定義：基本上就是讓llm幫忙做更聰明的檢索\n",
    "    - 傳統檢索：用戶問題 → 向量化 → 相似度搜尋 → 返回文件\n",
    "    - llm檢索：用戶問題 → llm理解與改寫 → 多角度搜尋 → llm篩選 → 返回文件\n",
    "- 優勢：\n",
    "    - 進一步理解用戶問題背後的意圖\n",
    "    - 傳統搜尋只會找到相似的詞彙\n",
    "- 幾種實踐方式：\n",
    "    - question expansion（問題擴展）：把一個用戶的問題擴展成ｎ個，幫助找到更全面的答案\n",
    "    - query rewriting（查詢改寫）：把模糊的問題改寫成更適合資料庫檢索的精確查詢\n",
    "    - multi-step reasoning（多步推理）：讓LLM分解複雜問題，逐步檢索\n",
    "    - SelfQuery（課本例子）:搜尋內容並篩選條件，例如「1980年有哪些關於外星人的電影？」會將查詢分成「外星人」，並且篩選條件為`eq('year', 1980)`提升精確度\n",
    "    - [進階]HyDE（Hypothetical Document Embeddings）：生成假想文件，然後用它來檢索\n",
    "    - [進階]]Self-RAG（自我反思檢索）：檢索後自我反思是否還需要更多訊息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f5bfd",
   "metadata": {},
   "source": [
    "### 課堂補充：優化策略 － Compression\n",
    "- 定義：檢索後壓縮的技術\n",
    "    - 流程：檢索回來的文件太多，llm把這些文件壓縮成最相關的核心資訊\n",
    "    - 只把壓縮後的精華內容丟給最終的生成回覆模型\n",
    "- 好處：\n",
    "    - llm有context window的限制\n",
    "    - 處理到上限值的量費用高\n",
    "    - 噪音干擾（返回完整chunk裡面可能很多和問題不相關的訊息）\n",
    "    - 效率低下，llm回覆時需要讀完全部的內容才能回答"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2569c6",
   "metadata": {},
   "source": [
    "## Vectorstore retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b15e5c-9b92-4d40-a149-b56335d330d9",
   "metadata": {
    "height": 166,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 載入環境\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c18f8a7b-62af-403e-9877-18d1c2265b4f",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install lark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d552e1",
   "metadata": {},
   "source": [
    "### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe368042",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 載入embedding資料庫（之前已經處理過的chunk已存在裡面）\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0189dc5",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3659e0f7",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "# 查詢裡面已經有209個chunks\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a807c758",
   "metadata": {
    "height": 112,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 接下來示範 mmr 的操作流程，先建立一些和蘑菇相關的文本\n",
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "715d54f3",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 建立一個小的蘑菇資料庫\n",
    "smalldb = Chroma.from_texts(texts, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a37b5a5",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 跟蘑菇有關的問題，要煮飯\n",
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3b025",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 先進行相似度的示範\n",
    "smalldb.similarity_search(question, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7502e10",
   "metadata": {},
   "source": [
    "結果：\n",
    "- [Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.', metadata={}),\n",
    " Document(page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).', metadata={})]\n",
    "\n",
    "\n",
    "\n",
    " 可以看到返回兩個結果並沒有包含到「有毒蘑菇」的相關資訊，這是很危險的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa6c0d",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.', metadata={}),\n",
       " Document(page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.', metadata={})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 接下來示範mmr搜尋，可以看到參數多了fetch_k，代表會預選3個資訊，再透過mmr選出２個\n",
    "smalldb.max_marginal_relevance_search(question,k=2, fetch_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf27fc8e",
   "metadata": {},
   "source": [
    "結果：\n",
    "- 可以發現返回的兩項裡面，其中一項被替換成其他的資訊"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a29e8c9",
   "metadata": {},
   "source": [
    "### Addressing Diversity: Maximum marginal relevance\n",
    "\n",
    "Last class we introduced one problem: how to enforce diversity in the search results.\n",
    " \n",
    "`Maximum marginal relevance` strives to achieve both relevance to the query *and diversity* among the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bb2c0a9",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs_ss = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f07f8793",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ss[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9f7e165",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ss[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee65105",
   "metadata": {},
   "source": [
    "##### 前情提要\n",
    "上一課時，我們故意示範了加入兩份重複的pdf進入到資料庫，結果發現用相似度檢索時，docs[0] & docs[1]返回了一模一樣的結果，這顯示了相似度的檢索是無法去重的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4ca1b6",
   "metadata": {},
   "source": [
    "Note the difference in results with `MMR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "222234c5",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93b20226",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17d39762",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'algorithm then? So what’s different? How come  I was making all that noise earlier about \\nleast squa'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ecbf22",
   "metadata": {},
   "source": [
    "##### 使用mmr的結果\n",
    "由於 mmr 會避免過於相近的文本成為回答的結果，因此可以看到複製的兩份文本即使都在資料庫中，也可以透過mmr的方式取除，因此上面兩項回答可以是不一樣的；這證明mmr某種程度上可以實現去重。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b909bc",
   "metadata": {},
   "source": [
    "### Addressing Specificity: working with metadata\n",
    "\n",
    "In last lecture, we showed that a question about the third lecture can include results from other lectures as well.\n",
    "\n",
    "To address this, many vectorstores support operations on `metadata`.\n",
    "\n",
    "`metadata` provides context for each embedded chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40569a98",
   "metadata": {},
   "source": [
    "##### 前情提要\n",
    "上一課時，另外一個檢索會出現的錯誤是想要找第三講的檔案內容，但檢索回來還包含其他講，這代表一般向量搜尋不理解邏輯條件。\n",
    "\n",
    "因此在這裡，我們嘗試透過手動提供filter來處理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c1a60b2",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 一樣的問題\n",
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8612840",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 手動加入filter\n",
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3,\n",
    "    filter={\"source\":\"docs/cs229_lectures/MachineLearning-Lecture03.pdf\"} # 一樣的向量查詢，但加上了meta data的過濾檢索\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97031876",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 0}\n",
      "{'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 14}\n",
      "{'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 4}\n"
     ]
    }
   ],
   "source": [
    "# 檢驗metadata來驗證來源，確實都來自第三講\n",
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc2d784",
   "metadata": {},
   "source": [
    "### Addressing Specificity: working with metadata using self-query retriever\n",
    "\n",
    "But we have an interesting challenge: we often want to infer the metadata from the query itself.\n",
    "\n",
    "To address this, we can use `SelfQueryRetriever`, which uses an LLM to extract:\n",
    " \n",
    "1. The `query` string to use for vector search\n",
    "2. A metadata filter to pass in as well\n",
    "\n",
    "Most vector databases support metadata filters, so this doesn't require any new databases or indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1d06084",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 接下來是 SelfQueryRetriever ，使用llm進行推斷\n",
    "# 載入 SelfQueryRetriever 和 AttributeInfo\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "# AttributeInfo: 提供llm meta data的架構\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0aa5e698",
   "metadata": {
    "height": 231,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 目的：教llm認識我的資料庫結構, 就像給llm一份資料的字典\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\", # 欄位名稱\n",
    "        description=\"The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`\", # 這欄的意義是什麼\n",
    "        type=\"string\", # 資料類型\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e143f05-908f-463d-a9de-408526c3947f",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Note:** The default model for `OpenAI` (\"from langchain.llms import OpenAI\") is `text-davinci-003`. Due to the deprication of OpenAI's model `text-davinci-003` on 4 January 2024, you'll be using OpenAI's recommended replacement model `gpt-3.5-turbo-instruct` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc9de693-7bdb-463e-b124-9f72163b0bd8",
   "metadata": {
    "height": 166,
    "tags": []
   },
   "outputs": [],
   "source": [
    "document_content_description = \"Lecture notes\" # 告訴llm文件內容是什麼（資料庫是關於什麼）\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm, # 剛剛的模型設定\n",
    "    vectordb, # 向量資料庫\n",
    "    document_content_description, # 剛剛的文件描述\n",
    "    metadata_field_info, # 剛剛建立的meta data 描述\n",
    "    verbose=True  # 顯示推理過程，後面就可以看到llm的思考過程\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79d781b9",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51778b0-1fcd-40a4-bd6b-0f13fec8acb1",
   "metadata": {},
   "source": [
    "**You will receive a warning** about predict_and_parse being deprecated the first time you executing the next line. This can be safely ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d4f9f7d",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query='regression' filter=Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='source', value='docs/cs229_lectures/MachineLearning-Lecture03.pdf') limit=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db04374e",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 14}\n",
      "{'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 0}\n",
      "{'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 10}\n",
      "{'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 10}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b8168",
   "metadata": {},
   "source": [
    "### Additional tricks: compression\n",
    "\n",
    "Another approach for improving the quality of retrieved docs is compression.\n",
    "\n",
    "Information most relevant to a query may be buried in a document with a lot of irrelevant text. \n",
    "\n",
    "Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
    "\n",
    "Contextual compression is meant to fix this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a060cf74",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "038649c8",
   "metadata": {
    "height": 78,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc686cf2",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wrap our vectorstore\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "compressor = LLMChainExtractor.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82794397",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cde86848",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "- \"those homeworks will be done in either MATLA B or in Octave\"\n",
      "- \"I know some people call it a free ve rsion of MATLAB\"\n",
      "- \"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data.\"\n",
      "- \"there's also a software package called Octave that you can download for free off the Internet.\"\n",
      "- \"it has somewhat fewer features than MATLAB, but it's free, and for the purposes of this class, it will work for just about everything.\"\n",
      "- \"once a colleague of mine at a different university, not at Stanford, actually teaches another machine learning course.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "- \"those homeworks will be done in either MATLA B or in Octave\"\n",
      "- \"I know some people call it a free ve rsion of MATLAB\"\n",
      "- \"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data.\"\n",
      "- \"there's also a software package called Octave that you can download for free off the Internet.\"\n",
      "- \"it has somewhat fewer features than MATLAB, but it's free, and for the purposes of this class, it will work for just about everything.\"\n",
      "- \"once a colleague of mine at a different university, not at Stanford, actually teaches another machine learning course.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "\"Oh, it was the MATLAB.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "\"Oh, it was the MATLAB.\"\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c4fc4d",
   "metadata": {},
   "source": [
    "## Combining various techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "161ae1ad",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e77ccae1",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "- \"those homeworks will be done in either MATLA B or in Octave\"\n",
      "- \"I know some people call it a free ve rsion of MATLAB\"\n",
      "- \"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data.\"\n",
      "- \"there's also a software package called Octave that you can download for free off the Internet.\"\n",
      "- \"it has somewhat fewer features than MATLAB, but it's free, and for the purposes of this class, it will work for just about everything.\"\n",
      "- \"once a colleague of mine at a different university, not at Stanford, actually teaches another machine learning course.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "\"Oh, it was the MATLAB.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "- learning algorithms to teach a car how to drive at reasonably high speeds off roads avoiding obstacles.\n",
      "- that's a robot program med by PhD student Eva Roshen to teach a sort of somewhat strangely configured robot how to get on top of an obstacle, how to get over an obstacle.\n",
      "- So I think all of these are robots that I think are very difficult to hand-code a controller for by learning these sorts of learning algorithms.\n",
      "- Just a couple more last things, but let me just check what questions you have right now.\n",
      "- So if there are no questions, I'll just close with two reminders, which are after class today or as you start to talk with other people in this class, I just encourage you again to start to form project partners, to try to find project partners to do your project with.\n",
      "- And also, this is a good time to start forming study groups, so either talk to your friends or post in the newsgroup, but we just encourage you to try to start to do both of those today, okay? Form study groups, and try to find two other project partners.\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2b63e1",
   "metadata": {},
   "source": [
    "## Other types of retrieval\n",
    "\n",
    "It's worth noting that vectordb as not the only kind of tool to retrieve documents. \n",
    "\n",
    "The `LangChain` retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83d2e808",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcf5b760",
   "metadata": {
    "height": 183,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load PDF\n",
    "loader = PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "joined_page_text=\" \".join(all_page_text)\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_text(joined_page_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9bb0d781",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b1cc35f",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"let me just check what questions you have righ t now. So if there are no questions, I'll just \\nclose with two reminders, which are after class today or as you start to talk with other \\npeople in this class, I just encourage you again to start to form project partners, to try to \\nfind project partners to do your project with. And also, this is a good time to start forming \\nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \\nencourage you to try to star t to do both of those today, okay? Form study groups, and try \\nto find two other project partners.  \\nSo thank you. I'm looking forward to teaching this class, and I'll see you in a couple of \\ndays.   [End of Audio]  \\nDuration: 69 minutes\", metadata={})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "docs_svm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a1659c0",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Saxena and Min Sun here did, wh ich is given an image like this, right? This is actually a \\npicture taken of the Stanford campus. You can apply that sort of cl ustering algorithm and \\ngroup the picture into regions. Let me actually blow that up so that you can see it more \\nclearly. Okay. So in the middle, you see the lines sort of groupi ng the image together, \\ngrouping the image into [inaudible] regions.  \\nAnd what Ashutosh and Min did was they then  applied the learning algorithm to say can \\nwe take this clustering and us e it to build a 3D model of the world? And so using the \\nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \\nworld looks like so that they could come up with a 3D model that you can sort of fly \\nthrough, okay? Although many people used to th ink it's not possible to take a single \\nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \\nalgorithm is the first step. They were able to.  \\nI'll just show you one more example. I like this  because it's a picture of Stanford with our \\nbeautiful Stanford campus. So again, taking th e same sort of clustering algorithms, taking \\nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \\nregions. And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.  You can sort of walk  into the ceiling, look\", metadata={})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "docs_tfidf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7885389e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
